
***We will be talking about how meta achieved 99.99999999% Cache Consistency***

Cache inconsistency feels like data loss from a user's perspective
Which made meta to create an ***observability solution***

	1. MonitoringðŸ“ˆ
	âœ¨ They created a simple service to monitor cache inconsistency and called it **Polaris**
	âœ¨ Okayyyy!! How Polaris work ??
		-> It acts like a cache server & receives cache invalidation events
		-> Then it queries cache servers to find data inconsistency
		-> It queues inconsistent cache servers & check again later.
		-> It checks data correctness during writes, so finding cache inconsistency will be faster.
		
![[polaris-meta.jpeg]]

	âœ¨ Besides thereâ€™s a risk of network partition between distributed cache & Polaris. So they use a separate invalidation event stream between the client & Polaris.
	âœ¨ A simple fix for cache inconsistency is to query the database.
	âœ¨ But thereâ€™s a risk of database overload at a high scale. So Polaris queries the database at timescales of 1, 5, or 10 minutes. It lets them back off efficiently & improve accuracy.

	2. Tracing ðŸ”
	âœ¨ Debugging Distributed cache without logs are hard as fcuk ðŸ¤¯
	âœ¨ But to find out why cache inconsistency occur each time, they could log every change...Though logging every data change isn't scalable as it's write-heavy, while cache is generally meant for a read-heavy workload
	
![[trace-meta-consistency-cache.jpeg]]

	âœ¨ Here' how we can solve this problem 
		-> We can log only when changes lead to race condition time window, making log storage cheaper.
		-> Maintaining index of recently modified data to determine if the next data change must be logged or not.
		-> Polaris reads logs if cache inconsistency is found & then sends notifications
	âœ¨ While absence of logs indicates a missing cache invalidation event.

***The bottom line:**Â Polaris finds cache inconsistency faster while tracing finds why it occurred.*

